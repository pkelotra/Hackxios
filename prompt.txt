üöÄ PROJECT GENERATION PROMPT (FULL WORKFLOW + ALL REQUIREMENTS)

I want you to generate a full-stack project based on the complete specification below.
The project is a health insurance denial-prevention and appeal assistant that uses:

PaddleOCR for extracting text

Llama-3-8B (via Groq API) for structured extraction & classification

Llama-3-70B (via Groq API) for reasoning & appeal letter generation

Everything in this prompt is final ‚Äî do not make assumptions outside this spec.
If something is missing, ask before generating.

üìå 1. Project Summary

Build a full-stack web app where patients upload medical bills, EOBs, denial letters, and doctor notes and interact with a chatbot.

The chatbot performs three core functions:

A) Pre-Claim Denial Prevention

User uploads bill + doctor note + selects insurance plan.
The system checks whether required documentation is missing for the claim.

B) Denial Explanation

User uploads denial letter.
System explains the denial reason in simple English.

C) Appeal Letter Generation

User uploads denial letter + doctor note + bill.
System generates an appeal letter PDF using extracted evidence.

All workflows rely on:

OCR ‚Üí Structured Extraction ‚Üí Reasoning ‚Üí Output

üìå 2. Required Model Stack (FREE & OPEN SOURCE)
‚úî OCR Model:

PaddleOCR

Use for all PDFs/images

‚úî LLM #1 (Extractor Model):

Llama-3-8B-Instruct (via Groq API)
Purpose:

Document classification

Extract CPT codes, ICD codes, patient name, dates, amounts

Extract denial codes (CO-50, CO-197, etc.)

Produce structured JSON

Precise extraction, no creativity

‚úî LLM #2 (Reasoning Model):

Llama-3-70B-Instruct (via Groq API)
Purpose:

Compare extracted data with insurance rules

Explain denial letters

Detect missing documentation

Draft professional appeal letters

Perform multi-document reasoning

üìå 3. System Workflow (IMPLEMENT EXACTLY THIS)
Step 1: Upload

User uploads multiple PDFs/images.

Step 2: OCR

Backend uses PaddleOCR to extract raw text.

Step 3: Document Classification (LLM-8B)

LLM identifies each file as:

medical_bill

eob

denial_letter

doctor_note

unknown

Step 4: Structured Extraction (LLM-8B)

For each document, extract fields:

doctor note

diagnosis

ICD code

symptoms

recommended procedure (CPT)

conservative treatments mentioned

dates

bill

CPT code

procedure name

amount charged

provider

date of service

EOB

amount billed

allowed amount

paid amount

adjustment code

patient responsibility

denial letter

denial reason

denial code (CO-50, CO-197‚Ä¶)

policy text excerpt

missing documentation

appeal deadline

Output stored as:

{
  "documents": [
    {
      "type": "denial_letter",
      "fields": {
        "patient": "",
        "denial_code": "",
        "denial_reason": "",
        "date_of_service": "",
        "procedure": "",
        "cpt": "",
        "policy_excerpt": ""
      }
    }
  ]
}

Step 5: Insurance Rule Matching

If user selected insurance plan, load JSON rule file:
(Example schema you must implement)

{
  "insurance": "Aetna PPO",
  "procedure_rules": {
    "72148": {
      "procedure": "Lumbar MRI",
      "requirements": [
        "6 weeks of conservative therapy",
        "Physical therapy notes",
        "Neurological exam findings",
        "X-ray prior to MRI"
      ]
    }
  }
}

Step 6: Reasoning Model (LLM-70B)
Case A ‚Äî Pre-Claim Analysis

Compare extracted documents with insurance rules

Identify missing items

Output a structured response including ‚Äúdenial risk score‚Äù

Case B ‚Äî Denial Explanation

Explain why denial happened

Extract the insurer‚Äôs logic

Give patient-friendly summary

Case C ‚Äî Appeal Letter

Draft a formal appeal letter using:

doctor note evidence

procedure details

denial code definitions

medical necessity justification

Final letter returned as PDF.

üìå 4. Backend Requirements

Use Python + FastAPI.

Implement endpoints:

POST /upload

Accepts multiple PDFs/images, stores them, runs OCR.

POST /analyze

Runs:

classification LLM

extraction LLM

reasoning LLM

POST /appeal-letter

Generates appeal letter PDF.

GET /insurance-plans

Returns list of JSON rule files.

Folder structure:
backend/
  ocr/
    paddle_ocr.py
  llm/
    extract_llm8b.py
    reasoning_llm70b.py
  insurance_rules/
    aetna_ppp.json
    bluecross_ppo.json
  models/
  routes/
    upload.py
    analyze.py
    appeal.py
  utils/
    pdf_tools.py
    text_cleaner.py

üìå 5. Frontend Requirements

Use React (Vite).

Features:

File upload dropzone

Chatbot interface

Display structured extraction

Show missing documentation

Denial explanation viewer

Download appeal letter PDF

Chat messages must show:

the user query

extracted file summaries

final reasoning result

üìå 6. Prompt Templates (MUST INCLUDE)
Document Classification Prompt
You are a classifier. Categorize the document into:
["medical_bill", "eob", "denial_letter", "doctor_note", "unknown"]

Return JSON:
{"type": "..."}

Extraction Prompt
You are an information extraction model.
Extract all medically relevant fields from the text.
Return ONLY valid JSON. No explanations.
<text>
...
</text>

Reasoning Prompt (Pre-Claim)
Compare extracted document fields with the insurance rule JSON.
Identify missing requirements, medical necessity flags,
and generate a denial risk percentage.
Return both plain English explanation and structured JSON.

Denial Explanation Prompt
Explain the denial reason based on the denial letter content.
Use simple English, identify implied missing documentation,
and cite any found evidence from doctor notes.

Appeal Letter Prompt
Draft a formal appeal letter citing extracted evidence, 
denial code definitions, procedure justification,
clinical findings, and insurance policy criteria.
Format professionally.

üìå 7. Deliverables

Your generated project must include:

Complete backend with FastAPI

PaddleOCR integration

Groq API integration for both Llama-3-8B and Llama-3-70B

React frontend chatbot

End-to-end pipeline: upload ‚Üí OCR ‚Üí classify ‚Üí extract ‚Üí reason ‚Üí answer

Insurance rule JSON examples

PDF generation for appeal letters

üìå 8. Important Constraints

All models must be free

Use Groq API keys for Llama models

PaddleOCR must run locally

Output must be deterministic and JSON-valid

No missing endpoints

No hallucinated file structure

Must handle multiple uploaded files at once

‚úîÔ∏è END OF SPECIFICATION ‚Äî generate the entire project based on this.